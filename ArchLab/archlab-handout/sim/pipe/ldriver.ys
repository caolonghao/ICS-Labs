#######################################################################
# Test for copying block of size 63;
#######################################################################
	.pos 0
main:	irmovq Stack, %rsp  	# Set up stack pointer

	# Set up arguments for copy function and then invoke it
	irmovq $63, %rdx		# src and dst have 63 elements
	irmovq dest, %rsi	# dst array
	irmovq src, %rdi	# src array
	call ncopy		 
	halt			# should halt with num nonzeros in %rax
StartFun:
#/* $begin ncopy-ys */
##################################################################
# ncopy.ys - Copy a src block of len words to dst.
# Return the number of positive words (>0) contained in src.
#
# Include your name and ID here.
#
# Describe how and why you modified the baseline code.
#
##################################################################
# Do not modify this portion
# Function prologue.
# %rdi = src , %rsi = dst, %rdx = len
ncopy:

##################################################################
# You can modify this portion
	# Loop header
	iaddq $-6,%rdx		# length -= 6
	jl REM

Loop:
    mrmovq (%rdi), %r10	# read val from src...
	mrmovq 8(%rdi),%r11
	rmmovq %r10, (%rsi)	# ...and store it to dst
	andq %r10, %r10		# val <= 0?
	jle Copy		# if so, goto Copy:
	iaddq $1,%rax
Copy:
	rmmovq %r11,8(%rsi)
	mrmovq 16(%rdi),%r10
	andq %r11,%r11
	jle Copy2
	iaddq $1,%rax
Copy2:
	mrmovq 24(%rdi),%r11
	rmmovq %r10, 16(%rsi)
	andq %r10,%r10
	jle Copy3
	iaddq $1,%rax
Copy3:
	rmmovq %r11,24(%rsi)
	mrmovq 32(%rdi),%r10
	andq %r11,%r11
	jle Copy4
	iaddq $1,%rax
Copy4:
	mrmovq 40(%rdi),%r11
	rmmovq %r10, 32(%rsi)
	andq %r10,%r10
	jle Copy5
	iaddq $1,%rax
Copy5:
	rmmovq %r11,40(%rsi)
	andq %r11,%r11
	jle nLoop
	iaddq $1,%rax
nLoop:
	iaddq $48,%rdi
	iaddq $48,%rsi
	iaddq $-6,%rdx
	jge Loop

REM:
	iaddq $5,%rdx
	jl Done
    mrmovq (%rdi), %r10
	mrmovq 8(%rdi),%r11
	rmmovq %r10, (%rsi)
	andq %r10,%r10
	jle RENPO
	iaddq $1,%rax
RENPO:
	iaddq $-1,%rdx
	jl Done
	rmmovq %r11,8(%rsi)
	andq %r11,%r11
	jle RENPO1
	iaddq $1,%rax
RENPO1:
	iaddq $-1,%rdx
	jl Done
    mrmovq 16(%rdi), %r10
	mrmovq 24(%rdi), %r11
	rmmovq %r10, 16(%rsi)
	andq %r10,%r10
	jle RENPO2
	iaddq $1,%rax
RENPO2:
	iaddq $-1,%rdx
	jl Done
	rmmovq %r11,24(%rsi)
	andq %r11,%r11
	jle Next
	iaddq $1,%rax
	Next:
		iaddq $-1,%rdx
		jl Done
		mrmovq 32(%rdi), %r10
		rmmovq %r10,32(%rsi)
		andq %r10,%r10
		jle Done
		iaddq $1,%rax
##################################################################
# Do not modify the following section of code
# Function epilogue.
Done:
	ret
##################################################################
# Keep the following label at the end of your function
End:
#/* $end ncopy-ys */
EndFun:

###############################
# Source and destination blocks 
###############################
	.align 8
src:
	.quad 1
	.quad 2
	.quad -3
	.quad -4
	.quad 5
	.quad 6
	.quad -7
	.quad 8
	.quad 9
	.quad -10
	.quad -11
	.quad 12
	.quad 13
	.quad 14
	.quad -15
	.quad -16
	.quad 17
	.quad 18
	.quad 19
	.quad -20
	.quad -21
	.quad -22
	.quad 23
	.quad 24
	.quad -25
	.quad -26
	.quad -27
	.quad 28
	.quad -29
	.quad -30
	.quad 31
	.quad 32
	.quad -33
	.quad -34
	.quad -35
	.quad -36
	.quad -37
	.quad 38
	.quad 39
	.quad 40
	.quad 41
	.quad -42
	.quad -43
	.quad -44
	.quad 45
	.quad 46
	.quad -47
	.quad 48
	.quad 49
	.quad -50
	.quad -51
	.quad -52
	.quad 53
	.quad -54
	.quad 55
	.quad 56
	.quad -57
	.quad -58
	.quad 59
	.quad -60
	.quad 61
	.quad 62
	.quad -63
	.quad 0xbcdefa # This shouldn't get moved

	.align 16
Predest:
	.quad 0xbcdefa
dest:
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
Postdest:
	.quad 0xdefabc

.align 8
# Run time stack
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0

Stack:
